{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c133905-1837-48c0-a8e8-47d0809800a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ROBERTA model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fa360-a177-4bd7-83d9-590e2c68e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "class ParaphraseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParaphraseModel, self).__init__()\n",
    "        self.bert = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        pooled_output = self.dropout(outputs.logits) \n",
    "        return outputs.loss, pooled_output\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_model = ParaphraseModel().to(device)\n",
    "best_model.load_state_dict(torch.load('best_model_fold.bin'))\n",
    "best_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d6db6-0173-4b97-afd1-8048ea89ed44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_texts(text1, text2, model, tokenizer, device, threshold=0.8):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text1, text2, add_special_tokens=True, max_length=128, truncation=True, padding='max_length', return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss, logits = model(input_ids, attention_mask)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(probs, dim=1).cpu().numpy()[0]\n",
    "        score = probs.cpu().numpy()[0][1]  # Probability of being a paraphrase\n",
    "\n",
    "    return score, \"Paraphrase\" if score > threshold else \"Not Paraphrase\"\n",
    "\n",
    "def display_results(text_pairs, model, tokenizer, device):\n",
    "    for text1, text2 in text_pairs:\n",
    "        score, result = compare_texts(text1, text2, model, tokenizer, device)\n",
    "        print(f\"Text 1: {text1}\\nText 2: {text2}\\nScore: {score:.2f}\\nResult: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d3563-63a0-4746-9472-f5181787f1a8",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c10763-967e-4df7-b267-cab2f01c4d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    # Cellular Respiration\n",
    "    \"Cellular respiration is the process by which cells break down glucose and other molecules from food in the presence of oxygen to produce ATP, which is the main energy currency of the cell. This process involves glycolysis, the citric acid cycle, and the electron transport chain.\",\n",
    "    \"In cellular respiration, cells convert glucose and other nutrients into ATP, the primary energy source, using oxygen. This process includes three main stages: glycolysis, the citric acid cycle, and the electron transport chain.\",\n",
    "    \"Cellular respiration is a crucial metabolic pathway that allows cells to extract energy from nutrients. This process begins with glycolysis in the cytoplasm, where glucose is broken down into pyruvate. The pyruvate then enters the mitochondria, where it undergoes the citric acid cycle and the electron transport chain, resulting in the production of ATP.\",\n",
    "    \"The process of cellular respiration involves several stages, starting with glycolysis in the cell's cytoplasm, where glucose is split into two molecules of pyruvate. These molecules are then transported into the mitochondria, where the citric acid cycle and the electron transport chain take place, producing ATP and releasing carbon dioxide and water as byproducts.\",\n",
    "    # # Photosynthesis\n",
    "    # \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll. It involves the intake of carbon dioxide and water, which are converted into glucose and oxygen.\",\n",
    "    # \"In photosynthesis, green plants and other organisms utilize sunlight to create food using chlorophyll. They take in carbon dioxide and water and convert them into glucose and oxygen.\",\n",
    "    # \"Photosynthesis is a complex process that takes place in the chloroplasts of plant cells. It involves several steps, starting with the absorption of light by chlorophyll, followed by the conversion of carbon dioxide and water into glucose and oxygen through the Calvin cycle.\",\n",
    "    # \"The process of photosynthesis in plants involves capturing light energy and converting it into chemical energy. This process starts with the absorption of light by chlorophyll and results in the production of glucose and oxygen from carbon dioxide and water.\",\n",
    "    # # Regular Exercise\n",
    "    # \"Regular exercise has numerous benefits, including improving cardiovascular health, enhancing muscle strength, and boosting mental well-being. Exercise helps in weight management, reduces the risk of chronic diseases, and improves sleep quality.\",\n",
    "    # \"Engaging in regular physical activity offers several advantages such as better heart health, stronger muscles, and improved mental health. It aids in maintaining a healthy weight, lowers the risk of chronic illnesses, and enhances sleep quality.\",\n",
    "    # \"Exercise provides many benefits like improving heart health, increasing muscle strength, and enhancing mental well-being. It can help with weight management, reduce the risk of diseases, and promote better sleep.\",\n",
    "    # \"Physical activity is beneficial for cardiovascular health, muscle strength, and mental health. It supports weight control, decreases the chances of chronic diseases, and helps with better sleep.\",\n",
    "    # # Water Cycle\n",
    "    # \"The water cycle is the continuous process by which water moves from the Earth's surface to the atmosphere and back. It includes processes such as evaporation, condensation, precipitation, and runoff.\",\n",
    "    # \"The hydrological cycle involves the movement of water between the Earth's surface and the atmosphere. Key stages include evaporation, where water turns into vapor; condensation, where vapor forms clouds; precipitation, where water falls as rain or snow; and runoff, where water flows back to bodies of water.\",\n",
    "    # \"The water cycle describes how water evaporates from the surface of the Earth, rises into the atmosphere, cools and condenses into rain or snow in clouds, and falls again to the surface as precipitation.\",\n",
    "    # \"The cycle of water involves evaporation, condensation, precipitation, and collection. Water from oceans, rivers, and lakes turns into vapor and rises into the atmosphere. This vapor forms clouds, which then precipitate as rain or snow, eventually returning the water to Earthâ€™s surface.\"\n",
    "]\n",
    "from itertools import combinations\n",
    "text_pairs = list(combinations(texts, 2))\n",
    "\n",
    "# Run the model and display results\n",
    "display_results(text_pairs, best_model, tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed7def",
   "metadata": {},
   "source": [
    "# Test texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851cdf8",
   "metadata": {},
   "source": [
    "Text 1 (Paraphrased):\n",
    "\"The process of cellular respiration involves breaking down glucose and other molecules from food to produce ATP, the main energy currency of cells. This process requires oxygen and includes stages such as glycolysis, the citric acid cycle, and the electron transport chain.\"\n",
    "\n",
    "Text 2 (Paraphrased):\n",
    "\"Cellular respiration is a method by which cells break down glucose and other food molecules in the presence of oxygen to generate ATP, the primary energy source for the cell. This involves glycolysis, the citric acid cycle, and the electron transport chain.\"\n",
    "\n",
    "Text 3 (Original):\n",
    "\"Photosynthesis in green plants involves capturing light energy and converting it into chemical energy in the form of glucose. This process takes place in the chloroplasts and requires carbon dioxide and water, releasing oxygen as a byproduct.\"\n",
    "\n",
    "Text 4 (Original):\n",
    "\"The water cycle describes the continuous movement of water on, above, and below the surface of the Earth. It includes processes such as evaporation, condensation, precipitation, and runoff, which help distribute water around the planet.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971f78b",
   "metadata": {},
   "source": [
    "Question: \"What are the benefits of a healthy diet?\"\n",
    "\n",
    "Paraphrased Answers:\n",
    "\n",
    "Text 1:\n",
    "A healthy diet provides numerous benefits, such as improving overall health, boosting energy levels, and maintaining a healthy weight. It reduces the risk of chronic diseases, enhances mental well-being, and supports a strong immune system.\n",
    "\n",
    "Text 2:\n",
    "Eating a healthy diet offers many advantages, including better overall health, increased energy, and weight management. It lowers the risk of chronic illnesses, improves mental health, and strengthens the immune system.\n",
    "\n",
    "Unique Answers:\n",
    "\n",
    "Text 3:\n",
    "A balanced diet rich in nutrients helps in maintaining optimal body functions, enhances mood, and promotes longevity. It is essential for the prevention of various health conditions and contributes to better physical and mental performance.\n",
    "\n",
    "Text 4:\n",
    "Consuming a diet that includes a variety of fruits, vegetables, whole grains, and lean proteins is crucial for sustaining good health. This kind of diet aids in the prevention of obesity, cardiovascular diseases, and diabetes, and it also supports cognitive function and overall vitality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f1d67",
   "metadata": {},
   "source": [
    "# Interface (RoBERTa and SBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591d49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://6cf0b9456880a70f65.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6cf0b9456880a70f65.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install sentence-transformers gradio plotly kaleido\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial.distance import cosine\n",
    "import plotly.express as px\n",
    "\n",
    "### RoBERTa Model Setup ###\n",
    "class ParaphraseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParaphraseModel, self).__init__()\n",
    "        self.bert = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return outputs.loss, pooled_output\n",
    "\n",
    "# Load RoBERTa model\n",
    "tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_model_roberta = ParaphraseModel().to(device)\n",
    "best_model_roberta.load_state_dict(torch.load('best_model_fold.bin', map_location=device))\n",
    "best_model_roberta.eval()\n",
    "\n",
    "def compare_texts_roberta(text1, text2, model, tokenizer, device):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text1, text2, add_special_tokens=True, max_length=128, truncation=True, padding='max_length', return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss, logits = model(input_ids, attention_mask)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        score = probs.cpu().numpy()[0][1]  # Probability of being a paraphrase\n",
    "\n",
    "    return score\n",
    "\n",
    "### SBERT Model Setup ###\n",
    "# Load the SBERT model\n",
    "model_sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load the model state dictionary if you have a saved model\n",
    "model_save_path = 'best_model_sbert.bin'\n",
    "model_sbert.load_state_dict(torch.load(model_save_path, map_location=torch.device('cpu')))\n",
    "model_sbert.eval()\n",
    "\n",
    "def compare_texts_sbert(text1, text2, model):\n",
    "    embeddings = model.encode([text1, text2], convert_to_tensor=True)\n",
    "    embeddings = embeddings.cpu()  # Move embeddings to CPU\n",
    "    cosine_sim = 1 - cosine(embeddings[0], embeddings[1])\n",
    "    return cosine_sim\n",
    "\n",
    "# Shared functions\n",
    "def update_dataframe(df):\n",
    "    df[\"Number\"] = range(1, len(df) + 1)\n",
    "    return df\n",
    "\n",
    "def check_similarity(df, model_choice):\n",
    "    texts = df[\"Answers\"].tolist()\n",
    "    n = len(texts)\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if model_choice == 'RoBERTa':\n",
    "                score = compare_texts_roberta(texts[i], texts[j], best_model_roberta, tokenizer_roberta, device)\n",
    "            else:\n",
    "                score = compare_texts_sbert(texts[i], texts[j], model_sbert)\n",
    "            similarity_matrix[i][j] = score\n",
    "            similarity_matrix[j][i] = score\n",
    "\n",
    "    clustering = AgglomerativeClustering(metric='precomputed', linkage='average', n_clusters=None, distance_threshold=0.2)\n",
    "    clusters = clustering.fit_predict(1 - similarity_matrix)  # Convert similarity to distance\n",
    "\n",
    "    cluster_texts = {i: [] for i in np.unique(clusters)}\n",
    "    cluster_scores = {i: [] for i in np.unique(clusters)}\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        cluster_texts[cluster_id].append(f\"Text {idx + 1}\")\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if clusters[i] == clusters[j]:\n",
    "                cluster_scores[clusters[i]].append(similarity_matrix[i][j])\n",
    "\n",
    "    cluster_data = {\n",
    "        \"Cluster\": [],\n",
    "        \"Texts\": [],\n",
    "        \"Average Similarity\": []\n",
    "    }\n",
    "\n",
    "    for cluster_id, texts in cluster_texts.items():\n",
    "        cluster_data[\"Cluster\"].append(cluster_id)\n",
    "        cluster_data[\"Texts\"].append(\", \".join(texts))\n",
    "        cluster_data[\"Average Similarity\"].append(np.mean(cluster_scores[cluster_id]) if cluster_scores[cluster_id] else 0)\n",
    "\n",
    "    # Create the MDS plot\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "    mds_results = mds.fit_transform(1 - similarity_matrix)  # Convert similarity to distance\n",
    "\n",
    "    fig = px.scatter(\n",
    "        x=mds_results[:, 0],\n",
    "        y=mds_results[:, 1],\n",
    "        color=[f\"Cluster {c}\" for c in clusters],  # Ensure clusters are treated as categorical\n",
    "        text=[f\"Text {i + 1}\" for i in range(n)],\n",
    "        labels={'color': 'Cluster'},\n",
    "        title=\"MDS Visualization of Text Clusters\"\n",
    "    )\n",
    "\n",
    "    # Update layout to show clusters as discrete categories with distinct colors\n",
    "    fig.update_traces(marker=dict(size=12, opacity=0.8))\n",
    "    fig.update_layout(\n",
    "        legend_title_text=\"Cluster\",\n",
    "        legend=dict(\n",
    "            itemsizing='constant',\n",
    "            title=dict(text=\"Cluster\"),\n",
    "            font=dict(size=12),\n",
    "        ),\n",
    "        coloraxis_showscale=False  # Disable the color scale bar\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(cluster_data), fig\n",
    "\n",
    "\n",
    "\n",
    "# HTML and markdown content for the interface\n",
    "intro_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<title>Paraphrase Detection Project</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Welcome to the Paraphrase Detection Project</h1>\n",
    "<p>My name is Sangjun Ko, and this project is part of my work as a member of the ATLAS Machine Learning Team at the University of Illinois Urbana-Champaign (UIUC).</p>\n",
    "<p>This project focuses on detecting paraphrases using advanced Natural Language Processing (NLP) techniques. I use pre-trained RoBERTa and SBERT models to analyze and compare different text inputs to determine if they are paraphrases of each other.</p>\n",
    "<h2>About NLP and Paraphrase Detection</h2>\n",
    "<p>Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful.</p>\n",
    "<p>Paraphrase detection is a specific task in NLP where the goal is to determine if two pieces of text have the same meaning but are expressed differently. This can be useful in various applications such as plagiarism detection, information retrieval, and question-answering systems.</p>\n",
    "<h2>Methods Used</h2>\n",
    "<ul>\n",
    "<li><strong>RoBERTa Model:</strong> A robustly optimized BERT approach, which is a state-of-the-art model for NLP tasks.</li>\n",
    "<li><strong>SBERT Model:</strong> A Sentence-BERT model for NLP tasks.</li>\n",
    "<li><strong>Hugging Face Transformers:</strong> I leverage the Transformers library by Hugging Face, which provides pre-trained models and tools for various NLP tasks.</li>\n",
    "<li><strong>Dataset Source:</strong> The dataset used for training the models is sourced from the <a href=\"https://www.microsoft.com/en-us/download/details.aspx?id=52398\" target=\"_blank\">Microsoft Paraphrase Corpus</a>.</li>\n",
    "</ul>\n",
    "<h2>Learn More</h2>\n",
    "<p>If you are interested in learning more about NLP and how to build projects like these, here are some resources:</p>\n",
    "<ul>\n",
    "<li><a href=\"https://www.coursera.org/specializations/natural-language-processing\" target=\"_blank\">Coursera: Natural Language Processing</a></li>\n",
    "<li><a href=\"https://huggingface.co/transformers/\" target=\"_blank\">Hugging Face Transformers Documentation</a></li>\n",
    "<li><a href=\"https://arxiv.org/abs/1907.11692\" target=\"_blank\">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></li>\n",
    "</ul>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "## Instructions\n",
    "1. Enter the texts you want to compare in the \"Input DataFrame\" below. \n",
    "2. Each row represents a different text.\n",
    "3. Select the model you want to use for comparison (RoBERTa or SBERT).\n",
    "4. Click the \"Check for Similarity\" button.\n",
    "5. The results will show the identified clusters and a visualization of the text similarities.\n",
    "\"\"\"\n",
    "\n",
    "description = \"\"\"\n",
    "## Interpretation Guide\n",
    "\n",
    "### Results DataFrame:\n",
    "The \"Paraphrase Check Results\" table lists the clusters identified among the input texts. Each row in the table represents a cluster, and the \"Texts\" column lists the text numbers that belong to that cluster.\n",
    "\n",
    "### Similarity Scores:\n",
    "The similarity between texts is calculated pairwise, with scores ranging from 0 to 1. A higher score indicates a higher probability that the texts are paraphrases of each other.\n",
    "\n",
    "### Cluster Visualization:\n",
    "The MDS visualization plot provides a graphical representation of the clusters. Each point corresponds to a text, and points that are closer together represent texts that are more similar to each other. The color indicates the cluster to which each text belongs.\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"Introduction\"):\n",
    "            gr.HTML(intro_html)\n",
    "        with gr.Tab(\"Paraphrase Detection\"):\n",
    "            gr.Markdown(\"# Paraphrase Detection Interface\")\n",
    "            gr.Markdown(instructions)\n",
    "            \n",
    "            data = {\n",
    "                \"Number\": [1, 2, 3, 4, 5],\n",
    "                \"Answers\": [\"\"] * 5  \n",
    "            }\n",
    "            dataframe_input = gr.Dataframe(value=pd.DataFrame(data), label=\"Input DataFrame\")\n",
    "            model_choice = gr.Dropdown(label=\"Select Model\", choices=[\"RoBERTa\", \"SBERT\"], value=\"RoBERTa\")\n",
    "\n",
    "            btn_check_similarity = gr.Button(\"Check for Similarity\")\n",
    "\n",
    "            gr.Markdown(description)\n",
    "            \n",
    "            results_output = gr.Dataframe(label=\"Paraphrase Check Results\")\n",
    "            plot_output = gr.Plot(label=\"Cluster Visualization\")\n",
    "\n",
    "            dataframe_input.change(fn=update_dataframe, inputs=dataframe_input, outputs=dataframe_input)\n",
    "\n",
    "            btn_check_similarity.click(\n",
    "                fn=check_similarity, \n",
    "                inputs=[dataframe_input, model_choice], \n",
    "                outputs=[results_output, plot_output]\n",
    "            )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db459372",
   "metadata": {},
   "source": [
    "**MDS**\n",
    "- Multidimensional Scaling is a technique used for dimensionality reduction. It seeks to place each object in N-dimensional space such that the between-object distances are preserved as well as possible. In this case, we use it to reduce our similarity matrix to 2 dimensions for visualization.\n",
    "- n_components=2: This specifies that we want to reduce our data to 2 dimensions, which is useful for visualization in a 2D plot.\n",
    "- dissimilarity=\"precomputed\": This indicates that we are providing a precomputed dissimilarity matrix rather than raw data. Our similarity_matrix is converted to a dissimilarity matrix by subtracting it from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca493e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
