{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d31b8f-678f-4e29-b5f9-ec84ac98bb58",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eba2fe1-a15a-49f3-acaf-c00d01c5dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/outputs.py:21: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.14.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Setting up a public link... we have recently upgraded the way public links are generated. If you encounter any problems, please report the issue and downgrade to gradio version 3.13.0\n",
      ".\n",
      "Running on public URL: https://0accc2b2-11a0-4a78.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0accc2b2-11a0-4a78.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Assuming the ParaphraseModel is defined as in your provided code\n",
    "class ParaphraseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParaphraseModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return outputs.loss, outputs.logits\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = ParaphraseModel()\n",
    "model.load_state_dict(torch.load(\"best_model_BERT.pth\"))  # Load your trained model weights\n",
    "model.eval()\n",
    "\n",
    "# Text cleaning and preprocessing functions\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize stop words and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word.lower() not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Define the function for Gradio interface with text cleaning and preprocessing\n",
    "def classify_paraphrase_BERT(text1, text2):\n",
    "    # Clean and preprocess the input texts\n",
    "    text1_cleaned = preprocess_text(clean_text(text1))\n",
    "    text2_cleaned = preprocess_text(clean_text(text2))\n",
    "\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text1_cleaned, text2_cleaned,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss, logits = model(input_ids, attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "    \n",
    "    return (\"True Paraphrase\" if pred == 0 else \"False Paraphrase\", confidence)\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_paraphrase_BERT,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=5, label=\"Text 1\"),\n",
    "        gr.inputs.Textbox(lines=5, label=\"Text 2\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Result\"),\n",
    "        gr.outputs.Textbox(label=\"Confidence\")\n",
    "    ],\n",
    "    title=\"Paraphrase Detection\",\n",
    "    description=\"Enter two sentences to check if they are paraphrases.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c133905-1837-48c0-a8e8-47d0809800a1",
   "metadata": {},
   "source": [
    "# ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839a2706-deb9-44ac-ba22-58a3b313f99d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/outputs.py:21: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.14.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Define the ParaphraseModel class using RoBERTa\n",
    "class ParaphraseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParaphraseModel, self).__init__()\n",
    "        self.bert = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return outputs.loss, outputs.logits\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = ParaphraseModel()\n",
    "model.load_state_dict(torch.load(\"best_model_ROBERTA.pth\"))  # Load your trained model weights\n",
    "model.eval()\n",
    "\n",
    "# Text cleaning and preprocessing functions\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize stop words and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word.lower() not in stop_words and len(word) > 1])\n",
    "    return text\n",
    "\n",
    "# Define the function for Gradio interface with text cleaning and preprocessing\n",
    "def classify_paraphrase_ROBERTA(text1, text2):\n",
    "    # Clean and preprocess the input texts\n",
    "    text1_cleaned = preprocess_text(clean_text(text1))\n",
    "    text2_cleaned = preprocess_text(clean_text(text2))\n",
    "\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text1_cleaned, text2_cleaned,\n",
    "        max_length=128,\n",
    "        add_special_tokens = True,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss, logits = model(input_ids, attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "    \n",
    "    return (\"True Paraphrase\" if pred == 0 else \"False Paraphrase\", confidence)\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_paraphrase_ROBERTA,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=5, label=\"Text 1\"),\n",
    "        gr.inputs.Textbox(lines=5, label=\"Text 2\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Result\"),\n",
    "        gr.outputs.Textbox(label=\"Confidence\")\n",
    "    ],\n",
    "    title=\"Paraphrase Detection\",\n",
    "    description=\"Enter two sentences to check if they are paraphrases.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "# iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6739091a-98ea-4d75-a2a6-786a457bf711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: A BMI of 25 or above is considered overweight; 30 or above is considered obese.\n",
      "Text 2: A BMI between 18.5 and 24.9 is considered normal, over 25 is considered overweight and 30 or greater is defined as obese.\n",
      "True Label: True Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.5239\n",
      "\n",
      "Text 1: The dollar was at 116.92 yen against the yen , flat on the session, and at 1.2891 against the Swiss franc , also flat.\n",
      "Text 2: The dollar was at 116.78 yen JPY= , virtually flat on the session, and at 1.2871 against the Swiss franc CHF= , down 0.1 percent.\n",
      "True Label: True Paraphrase\n",
      "Prediction: True Paraphrase, Confidence: 0.7190\n",
      "\n",
      "Text 1: Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\n",
      "Text 2: But six months ago, the two sides managed to strike a $6.8-billion debt rollover deal, which expires in August.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9101\n",
      "\n",
      "Text 1: Inhibited children tend to be timid with new people, objects, and situations, while uninhibited children spontaneously approach them.\n",
      "Text 2: Simply put, shy individuals tend to be more timid with new people and situations.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.7315\n",
      "\n",
      "Text 1: I wanted to bring the most beautiful people into the most beautiful building, he said Sunday inside the Grand Central concourse.\n",
      "Text 2: \"I wanted to bring the most beautiful people into the most beautiful building,\" Tunick said Sunday.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9772\n",
      "\n",
      "Text 1: The broad Standard & Poor's 500 <.SPX> fell 10.75 points, or 1.02 percent, to 1,039.32.\n",
      "Text 2: The S&P 500 index was up 1.26, or 0.1 percent, to 1,039.32 after sinking 10.75 yesterday.\n",
      "True Label: True Paraphrase\n",
      "Prediction: True Paraphrase, Confidence: 0.8495\n",
      "\n",
      "Text 1: Duque will return to Earth Oct. 27 with the station's current crew, U.S. astronaut Ed Lu and Russian cosmonaut Yuri Malenchenko.\n",
      "Text 2: Currently living onboard the space station are American astronaut Ed Lu and Russian cosmonaut Yuri Malenchenko.\n",
      "True Label: True Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.5184\n",
      "\n",
      "Text 1: Singapore is already the United States' 12th-largest trading partner, with two-way trade totaling more than $34 billion.\n",
      "Text 2: Although a small city-state, Singapore is the 12th-largest trading partner of the United States, with trade volume of $33.4 billion last year.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.8695\n",
      "\n",
      "Text 1: The AFL-CIO is waiting until October to decide if it will endorse a candidate.\n",
      "Text 2: The AFL-CIO announced Wednesday that it will decide in October whether to endorse a candidate before the primaries.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.8839\n",
      "\n",
      "Text 1: No dates have been set for the civil or the criminal trial.\n",
      "Text 2: No dates have been set for the criminal or civil cases, but Shanley has pleaded not guilty.\n",
      "True Label: True Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.6623\n",
      "\n",
      "Text 1: The largest gains were seen in prices, new orders, inventories and exports.\n",
      "Text 2: Sub-indexes measuring prices, new orders, inventories and exports increased.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.6606\n",
      "\n",
      "Text 1: Trading in Loral was halted yesterday; the shares closed on Monday at $3.01.\n",
      "Text 2: The New York Stock Exchange suspended trading yesterday in Loral, which closed at $3.01 Friday.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.7156\n",
      "\n",
      "Text 1: Earnings per share from recurring operations will be 13 cents to 14 cents.\n",
      "Text 2: That beat the company's April earnings forecast of 8 to 9 cents a share.\n",
      "True Label: True Paraphrase\n",
      "Prediction: True Paraphrase, Confidence: 0.6154\n",
      "\n",
      "Text 1: He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\n",
      "Text 2: After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9085\n",
      "\n",
      "Text 1: Retailers J.C. Penney Co. Inc. (JCP) and Walgreen Co. (WAG) kick things off on Monday.\n",
      "Text 2: Retailers J.C. Penney Co. Inc. JCP.N and Walgreen Co. WAG.N kick things off on Monday.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9863\n",
      "\n",
      "Text 1: Prosecutors filed a motion informing Lee they intend to seek the death penalty.\n",
      "Text 2: He added that prosecutors will seek the death penalty.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.6188\n",
      "\n",
      "Text 1: Last year the court upheld Cleveland's school voucher program, ruling 5-4 that vouchers are constitutional if they provide parents a choice of religious and secular schools.\n",
      "Text 2: Last year, the court ruled 5-4 in an Ohio case that government vouchers are constitutional if they provide parents with choices among a range of religious and secular schools.\n",
      "True Label: True Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9768\n",
      "\n",
      "Text 1: He beat testicular cancer that had spread to his lungs and brain.\n",
      "Text 2: Armstrong, 31, battled testicular cancer that spread to his brain.\n",
      "True Label: True Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.8084\n",
      "\n",
      "Text 1: Sorkin, who faces charges of conspiracy to obstruct justice and lying to a grand jury, was to have been tried separately.\n",
      "Text 2: Sorkin was to have been tried separately on charges of conspiracy and lying to a grand jury.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9840\n",
      "\n",
      "Text 1: Graves reported from Albuquerque, Villafranca from Austin and Ratcliffe from Laredo.\n",
      "Text 2: Pete Slover reported from Laredo and Gromer Jeffers from Albuquerque.\n",
      "True Label: True Paraphrase\n",
      "Prediction: True Paraphrase, Confidence: 0.5621\n",
      "\n",
      "Text 1: The US chip market is expected to decline 2.1 percent this year, then grow 15.7 percent in 2004.\n",
      "Text 2: The Americas market will decline 2.1 percent to $30.6 billion in 2003, and then grow 15.7 percent to $35.4 billion in 2004.\n",
      "True Label: False Paraphrase\n",
      "Prediction: True Paraphrase, Confidence: 0.5679\n",
      "\n",
      "Text 1: The group will be headed by State Department official John S. Wolf, who has served in Australia, Vietnam, Greece and Pakistan.\n",
      "Text 2: The group will be headed by John S. Wolf, an assistant secretary of state who has served in Australia, Vietnam, Greece and Pakistan.\n",
      "True Label: True Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9849\n",
      "\n",
      "Text 1: The commission must work out the plan's details, but the average residential customer paying $840 a year would get a savings of about $30 annually.\n",
      "Text 2: An average residential customer paying $840 a year for electricity could see a savings of $30 annually.\n",
      "True Label: False Paraphrase\n",
      "Prediction: True Paraphrase, Confidence: 0.5709\n",
      "\n",
      "Text 1: The company has said it plans to restate its earnings for 2000 through 2002.\n",
      "Text 2: The company had announced in January that it would have to restate earnings for 2002, 2001 and perhaps 2000.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9279\n",
      "\n",
      "Text 1: Results from No. 2 U.S. soft drink maker PepsiCo Inc. PEP.N were likely to be in the spotlight.\n",
      "Text 2: Results from No. 2 U.S. soft drink maker PepsiCo Inc. (nyse: PEP - news - people) were likely to be in the spotlight.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9659\n",
      "\n",
      "Text 1: The result is an overall package that will provide significant economic growth for our employees over the next four years.\n",
      "Text 2: \"The result is an overall package that will provide a significant economic growth for our employees over the next few years,\" he said.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9833\n",
      "\n",
      "Text 1: Wal-Mart said it would check all of its million-plus domestic workers to ensure they were legally employed.\n",
      "Text 2: It has also said it would review all of its domestic employees more than 1 million to ensure they have legal status.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9766\n",
      "\n",
      "Text 1: The songs are on offer for 99 cents each, or $9.99 for an album.\n",
      "Text 2: The company will offer songs for 99 cents and albums for $9.95.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9759\n",
      "\n",
      "Text 1: However, the talk was downplayed by PBL which said it would focus only on smaller purchases that were immediately earnings and cash flow accretive.\n",
      "Text 2: The talk, however,has been downplayed by PBL which said it would focus only on smaller purchases that were immediately earnings and cash flow-accretive.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.9842\n",
      "\n",
      "Text 1: Comcast Class A shares were up 8 cents at $30.50 in morning trading on the Nasdaq Stock Market.\n",
      "Text 2: The stock rose 48 cents to $30 yesterday in Nasdaq Stock Market trading.\n",
      "True Label: False Paraphrase\n",
      "Prediction: False Paraphrase, Confidence: 0.6003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model with provided examples\n",
    "test_data = [\n",
    "    (\"A BMI of 25 or above is considered overweight; 30 or above is considered obese.\", \"A BMI between 18.5 and 24.9 is considered normal, over 25 is considered overweight and 30 or greater is defined as obese.\", 0),\n",
    "    (\"The dollar was at 116.92 yen against the yen , flat on the session, and at 1.2891 against the Swiss franc , also flat.\", \"The dollar was at 116.78 yen JPY= , virtually flat on the session, and at 1.2871 against the Swiss franc CHF= , down 0.1 percent.\", 0),\n",
    "    (\"Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\", \"But six months ago, the two sides managed to strike a $6.8-billion debt rollover deal, which expires in August.\", 1),\n",
    "    (\"Inhibited children tend to be timid with new people, objects, and situations, while uninhibited children spontaneously approach them.\", \"Simply put, shy individuals tend to be more timid with new people and situations.\", 1),\n",
    "    (\"I wanted to bring the most beautiful people into the most beautiful building, he said Sunday inside the Grand Central concourse.\", \"\\\"I wanted to bring the most beautiful people into the most beautiful building,\\\" Tunick said Sunday.\", 1),\n",
    "    (\"The broad Standard & Poor's 500 <.SPX> fell 10.75 points, or 1.02 percent, to 1,039.32.\", \"The S&P 500 index was up 1.26, or 0.1 percent, to 1,039.32 after sinking 10.75 yesterday.\", 0),\n",
    "    (\"Duque will return to Earth Oct. 27 with the station's current crew, U.S. astronaut Ed Lu and Russian cosmonaut Yuri Malenchenko.\", \"Currently living onboard the space station are American astronaut Ed Lu and Russian cosmonaut Yuri Malenchenko.\", 0),\n",
    "    (\"Singapore is already the United States' 12th-largest trading partner, with two-way trade totaling more than $34 billion.\", \"Although a small city-state, Singapore is the 12th-largest trading partner of the United States, with trade volume of $33.4 billion last year.\", 1),\n",
    "    (\"The AFL-CIO is waiting until October to decide if it will endorse a candidate.\", \"The AFL-CIO announced Wednesday that it will decide in October whether to endorse a candidate before the primaries.\", 1),\n",
    "    (\"No dates have been set for the civil or the criminal trial.\", \"No dates have been set for the criminal or civil cases, but Shanley has pleaded not guilty.\", 0),\n",
    "    (\"The largest gains were seen in prices, new orders, inventories and exports.\", \"Sub-indexes measuring prices, new orders, inventories and exports increased.\", 1),\n",
    "    (\"Trading in Loral was halted yesterday; the shares closed on Monday at $3.01.\", \"The New York Stock Exchange suspended trading yesterday in Loral, which closed at $3.01 Friday.\", 1),\n",
    "    (\"Earnings per share from recurring operations will be 13 cents to 14 cents.\", \"That beat the company's April earnings forecast of 8 to 9 cents a share.\", 0),\n",
    "    (\"He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\", \"After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\", 1),\n",
    "    (\"Retailers J.C. Penney Co. Inc. (JCP) and Walgreen Co. (WAG) kick things off on Monday.\", \"Retailers J.C. Penney Co. Inc. JCP.N and Walgreen Co. WAG.N kick things off on Monday.\", 1),\n",
    "    (\"Prosecutors filed a motion informing Lee they intend to seek the death penalty.\", \"He added that prosecutors will seek the death penalty.\", 1),\n",
    "    (\"Last year the court upheld Cleveland's school voucher program, ruling 5-4 that vouchers are constitutional if they provide parents a choice of religious and secular schools.\", \"Last year, the court ruled 5-4 in an Ohio case that government vouchers are constitutional if they provide parents with choices among a range of religious and secular schools.\", 0),\n",
    "    (\"He beat testicular cancer that had spread to his lungs and brain.\", \"Armstrong, 31, battled testicular cancer that spread to his brain.\", 0),\n",
    "    (\"Sorkin, who faces charges of conspiracy to obstruct justice and lying to a grand jury, was to have been tried separately.\", \"Sorkin was to have been tried separately on charges of conspiracy and lying to a grand jury.\", 1),\n",
    "    (\"Graves reported from Albuquerque, Villafranca from Austin and Ratcliffe from Laredo.\", \"Pete Slover reported from Laredo and Gromer Jeffers from Albuquerque.\", 0),\n",
    "    (\"The US chip market is expected to decline 2.1 percent this year, then grow 15.7 percent in 2004.\", \"The Americas market will decline 2.1 percent to $30.6 billion in 2003, and then grow 15.7 percent to $35.4 billion in 2004.\", 1),\n",
    "    (\"The group will be headed by State Department official John S. Wolf, who has served in Australia, Vietnam, Greece and Pakistan.\", \"The group will be headed by John S. Wolf, an assistant secretary of state who has served in Australia, Vietnam, Greece and Pakistan.\", 0),\n",
    "    (\"The commission must work out the plan's details, but the average residential customer paying $840 a year would get a savings of about $30 annually.\", \"An average residential customer paying $840 a year for electricity could see a savings of $30 annually.\", 1),\n",
    "    (\"The company has said it plans to restate its earnings for 2000 through 2002.\", \"The company had announced in January that it would have to restate earnings for 2002, 2001 and perhaps 2000.\", 1),\n",
    "    (\"Results from No. 2 U.S. soft drink maker PepsiCo Inc. PEP.N were likely to be in the spotlight.\", \"Results from No. 2 U.S. soft drink maker PepsiCo Inc. (nyse: PEP - news - people) were likely to be in the spotlight.\", 1),\n",
    "    (\"The result is an overall package that will provide significant economic growth for our employees over the next four years.\", \"\\\"The result is an overall package that will provide a significant economic growth for our employees over the next few years,\\\" he said.\", 1),\n",
    "    (\"Wal-Mart said it would check all of its million-plus domestic workers to ensure they were legally employed.\", \"It has also said it would review all of its domestic employees more than 1 million to ensure they have legal status.\", 1),\n",
    "    (\"The songs are on offer for 99 cents each, or $9.99 for an album.\", \"The company will offer songs for 99 cents and albums for $9.95.\", 1),\n",
    "    (\"However, the talk was downplayed by PBL which said it would focus only on smaller purchases that were immediately earnings and cash flow accretive.\", \"The talk, however,has been downplayed by PBL which said it would focus only on smaller purchases that were immediately earnings and cash flow-accretive.\", 1),\n",
    "    (\"Comcast Class A shares were up 8 cents at $30.50 in morning trading on the Nasdaq Stock Market.\", \"The stock rose 48 cents to $30 yesterday in Nasdaq Stock Market trading.\", 1)\n",
    "]\n",
    "\n",
    "for text1, text2, true_label in test_data:\n",
    "    prediction, confidence = classify_paraphrase_ROBERTA(text1, text2)\n",
    "    print(f\"Text 1: {text1}\\nText 2: {text2}\\nTrue Label: {'True Paraphrase' if true_label == 0 else 'False Paraphrase'}\")\n",
    "    print(f\"Prediction: {prediction}, Confidence: {confidence:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fa360-a177-4bd7-83d9-590e2c68e7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
